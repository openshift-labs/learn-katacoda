# Observing the Service Mesh using Kiali

Applications deployed within the Service Mesh are able to take advantage of
the built-in tracing and monitoring features present in the control plane.
These features provide an invaluable insight into the organisation and
operation of the application as well as the application's performance.

## What we will learn in this module

This module will provide a brief introduction to the Kiali observability
component within the Service Mesh control plane.

## Kiali

link:http://kiali.io[Kiali] is a component which visualizes an application's
topology, health, metrics and tracing information to provide a deeper
understanding of the application's behaviour and performance. Within a single
view it is easy to determine which services are communicating with each
other, where the traffic is flowing, information about the current health of
the service and other useful metrics.

Kiali also integrates with Jaeger to provide access to distributed tracing
information, allowing you to track an individual request as it flows through
the system and identify potential issues.

### How does Kiali work?

Every pod deployed as part of the Service Mesh contains a proxy container
responsible for intercepting the application traffic coming into and going
out of the pod. The Service Mesh proxy is automatically created on deployment
of the application and automatically captures information as part of each
service invocation. Kiali uses this information to provide a visualization of
the Service Mesh behaviour. The information includes metrics as well as
distributed tracing information.

### Opening the Kiali console

To open the Kiali console get the link from the following command. Open it in
a new tab. Make sure to use HTTPS to access.

[source,bash,role#"execute-1"]
----
echo https://$(oc get route -n %username%-smcp kiali -o 'jsonpath#{.spec.host}')
----

When prompted to login use the same username and password you used to access OpenShift.

### Generating load

Before we take a look at the Kiali console lets first generate some load on
the Service Mesh. Let's execute the following in terminal 2 (the lower terminal)

[source,bash,role#"execute-2"]
----
bash /opt/app-root/workshop/content/scripts/curl_customer_quiet.sh
----

### Kiali's Graph

Within the Kiali UI select the _Graph_ option from the left hand navigation
and then choose

* Namespace: %username%-tutorial
* Versioned app graph
* Requests percentage
* Last 1m
* Every 10s

image:images/kiali-graph-1.png[Kiali Graph showing configuration]

You should now see the application graph showing traffic being created by our
script generating load. The traffic will flow from the Service Mesh ingress
gateway to the customer service, preference service and finally the
recommendation service. The request percentage will show _100%_ on each edge
except within the recommendation service where the traffic should be split
evenly across all three versions.

image:images/kiali-graph-2.png[Kiali Graph showing application traffic]

### Kiali's View of Jaeger Distributed Tracing

Jaeger is an end-to-end distributed tracing tool, providing insight into
transactions, performance and latency, root cause analysis, and more.

Kiali has the capability to expose a view of Jager Distributed Tracing. This
involves the use of an `iframe`. As you saw when you logged into Kiali, you
had to accept self-signed certificates and allow Kiali to use your user
(`%username%`) permissions to talk to OpenShift. Becuase Kiali is exposing
Jaeger via an `iframe`, you first need to visit Jaeger to accept the
self-signed certificates and grant it permissions.

[source,bash,role#"execute-1"]
----
echo https://$(oc get route -n %username%-smcp jaeger -o 'jsonpath#{.spec.host}')
----

Open this URL in another browser tab, accept all certificates and, when
prompted, login with the same user and password that you used to login to
OpenShift. Once you are done, you can return to the browser tab where you
have Kiali open.

Within the Kiali UI select the _Distributed Tracing_ option from the left
hand navigation and then choose

* Namespace: %username%-tutorial
* Service: %username%-tutorial -> customer

and finally press the _Search_ button.

image:images/kiali-tracing-1.png[Kiali Tracing showing configuration]

You should now see a list of the 20 most recent invocations of the customer service.

image:images/kiali-tracing-2.png[Kiali Tracing showing invocations]

Select one of the invocations to see more information. The graph should now
show a hierarchy of the invocations with those spans highlighted in _red_
automatically captured by the Service Mesh proxy, both client and server
side, and the remainder provided by the application.

image:images/kiali-tracing-3.png[Kiali Tracing showing detailed invocation]

Each span can be expanded to show more contextual information captured as part of the tracing.

### Cleaning up

Click into the lower terminal that is still silently executing the script we
used to generate load. Press the ctrl+c keys to terminate the script.

## What we learned in this module

Kiali is a very useful tool for visualizing the behaviour of your Service
Mesh. Through one UI you not only have a consistent view of your service
interactions but you can see more detailed information about those
invocations helping you to understand and identify potential issues which may
arise.

With an understanding of Kiali you should now be able to make use of its
capabilities within the following modules to visualize the changes in
behaviour we will make through the resources within the Service Mesh
framework. Please keep your Kiali UI open as you work through the following
modules.

Kiali provides additional capabilities beyond what we have explored in this
module, for more information refer to the link:http://kiali.io[Kiali
website].
